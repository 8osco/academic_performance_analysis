{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22c29f46",
   "metadata": {},
   "source": [
    "# **Prediction model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc85ea",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Build model to predict students' performance based on the data available.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Cleaned data saved in https://github.com/8osco/academic_performance_analysis/blob/main/data/inputs/cleaned/edu_data_cleaned.csv\n",
    "* Initial analyses performed in [1_data_etl.ipynb](https://github.com/8osco/academic_performance_analysis/blob/main/jupyter_notebooks/1_data_etl.ipynb)\n",
    "* Exploratory data analysis performed in [2_exploratory_analysis](https://github.com/8osco/academic_performance_analysis/blob/main/jupyter_notebooks/2_exploratory_analysis.ipynb)\n",
    "* Hypothesis testing performed in [3_hypothesis_testing] (https://github.com/8osco/academic_performance_analysis/blob/main/jupyter_notebooks/3_hypothesis_testing.ipynb)\n",
    "\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Prediction model and key drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7b087",
   "metadata": {},
   "source": [
    "# 1 Import packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96d041",
   "metadata": {},
   "source": [
    "Import relevant packages required for data analysis and visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe4420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NumPy, Pandas, Matplotlib, Seaborn and Plotly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c48893",
   "metadata": {},
   "source": [
    "# 2 Data extract and familiarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94876852",
   "metadata": {},
   "source": [
    "Read in the cleaned csv file and familiarise with the file structure at a high level, through use of various dataframe methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613af697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>nationality</th>\n",
       "      <th>place_of_birth</th>\n",
       "      <th>education_stage</th>\n",
       "      <th>grade</th>\n",
       "      <th>classroom_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>semester</th>\n",
       "      <th>parent_involved</th>\n",
       "      <th>raised_hands</th>\n",
       "      <th>resource_visits</th>\n",
       "      <th>announcements_viewed</th>\n",
       "      <th>discussion_participation</th>\n",
       "      <th>parent_answered_survey</th>\n",
       "      <th>parent_school_satisfaction</th>\n",
       "      <th>absence_category</th>\n",
       "      <th>pass_fail_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>lowerschool</td>\n",
       "      <td>g-04</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "      <td>first</td>\n",
       "      <td>father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "      <td>low</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>lowerschool</td>\n",
       "      <td>g-04</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "      <td>first</td>\n",
       "      <td>father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "      <td>low</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>lowerschool</td>\n",
       "      <td>g-04</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "      <td>first</td>\n",
       "      <td>father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>no</td>\n",
       "      <td>bad</td>\n",
       "      <td>high</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>lowerschool</td>\n",
       "      <td>g-04</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "      <td>first</td>\n",
       "      <td>father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>no</td>\n",
       "      <td>bad</td>\n",
       "      <td>high</td>\n",
       "      <td>fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>kuwait</td>\n",
       "      <td>lowerschool</td>\n",
       "      <td>g-04</td>\n",
       "      <td>a</td>\n",
       "      <td>it</td>\n",
       "      <td>first</td>\n",
       "      <td>father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>no</td>\n",
       "      <td>bad</td>\n",
       "      <td>high</td>\n",
       "      <td>pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender nationality place_of_birth education_stage grade classroom_id  \\\n",
       "0   male      kuwait         kuwait     lowerschool  g-04            a   \n",
       "1   male      kuwait         kuwait     lowerschool  g-04            a   \n",
       "2   male      kuwait         kuwait     lowerschool  g-04            a   \n",
       "3   male      kuwait         kuwait     lowerschool  g-04            a   \n",
       "4   male      kuwait         kuwait     lowerschool  g-04            a   \n",
       "\n",
       "  subject semester parent_involved  raised_hands  resource_visits  \\\n",
       "0      it    first          father            15               16   \n",
       "1      it    first          father            20               20   \n",
       "2      it    first          father            10                7   \n",
       "3      it    first          father            30               25   \n",
       "4      it    first          father            40               50   \n",
       "\n",
       "   announcements_viewed  discussion_participation parent_answered_survey  \\\n",
       "0                     2                        20                    yes   \n",
       "1                     3                        25                    yes   \n",
       "2                     0                        30                     no   \n",
       "3                     5                        35                     no   \n",
       "4                    12                        50                     no   \n",
       "\n",
       "  parent_school_satisfaction absence_category pass_fail_status  \n",
       "0                       good              low             pass  \n",
       "1                       good              low             pass  \n",
       "2                        bad             high             fail  \n",
       "3                        bad             high             fail  \n",
       "4                        bad             high             pass  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and display the first few rows\n",
    "df = pd.read_csv('../data/inputs/cleaned/edu_data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e8db32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the shape of the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178368c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   gender                      478 non-null    object\n",
      " 1   nationality                 478 non-null    object\n",
      " 2   place_of_birth              478 non-null    object\n",
      " 3   education_stage             478 non-null    object\n",
      " 4   grade                       478 non-null    object\n",
      " 5   classroom_id                478 non-null    object\n",
      " 6   subject                     478 non-null    object\n",
      " 7   semester                    478 non-null    object\n",
      " 8   parent_involved             478 non-null    object\n",
      " 9   raised_hands                478 non-null    int64 \n",
      " 10  resource_visits             478 non-null    int64 \n",
      " 11  announcements_viewed        478 non-null    int64 \n",
      " 12  discussion_participation    478 non-null    int64 \n",
      " 13  parent_answered_survey      478 non-null    object\n",
      " 14  parent_school_satisfaction  478 non-null    object\n",
      " 15  absence_category            478 non-null    object\n",
      " 16  pass_fail_status            478 non-null    object\n",
      "dtypes: int64(4), object(13)\n",
      "memory usage: 63.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display the column data types and check for null or missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7582a1",
   "metadata": {},
   "source": [
    "# 3 Model build and performance assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be42ed",
   "metadata": {},
   "source": [
    "As the goal is to predict if a student will pass or fail based on the independent variables available in the dataset, we are working with categorical variables and so we will build a classification model.\n",
    "\n",
    "There are some classification model choices and we will start with logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9335821",
   "metadata": {},
   "source": [
    "Step 1 - data readiness check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbbbc0",
   "metadata": {},
   "source": [
    "We have already converted student performances into pass and fail categories in the data cleaning section earlier (refer to 1_data_etl.ipynb), and so we can work on the next steps.\n",
    "\n",
    "We can also consider feature selection to improve model performance, e.g. dropping the grade column as education_stage column could be sufficiently representative and is more generic for modelling purposes. We hold off making changes at this stage, and can examine how feature selection can improve model performance at a later time. We should also remind ourselves that there is a potential typo/misclassification of grade for one of the data records, which has not been treated yet. Feature scaling (e.g. normalisation) is not required, as per the comparison we have looked at in 1_data_etl.ipynb indicated that the value ranges are similar amongst the numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1655fe",
   "metadata": {},
   "source": [
    "Step 2 - split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44977ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function to split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                    df.drop(['pass_fail_status'], axis=1),\n",
    "                                    df['pass_fail_status'],\n",
    "                                    test_size=0.2, # split 80% for training and 20% for testing\n",
    "                                    random_state=101 # set random state for reproducibility\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e85ae",
   "metadata": {},
   "source": [
    "Step 3 - encoding categorical variables fo machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f1e69",
   "metadata": {},
   "source": [
    "As we will be deploying machine learning tools, numerical encoding for the categorical variables are necessary. \n",
    "\n",
    "We did not proceed with this in the data cleaning section, as we prioritised descriptiveness of column values over this as mentioned. \n",
    "\n",
    "We will use feature_engine to encode automatically and create a Scikit-learn pipeline to run this and the logistic regression model. One hot encoding is chosen, as it is very commonly used in logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2256b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define categorical variables, excluding pass_fail_status as it is the target variable\n",
    "cat_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Create pipeline for one-hot encoding and logistic regression model\n",
    "pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder(variables=cat_cols, drop_last=True)), # one-hot encoding for categorical variables, dropping the last category as it is redundant\n",
    "    ('model', LogisticRegression(max_iter=1000)) # logistic regression model with increased max_iter for convergence\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21becfe7",
   "metadata": {},
   "source": [
    "Step 4 - Perform training and testing ans evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcc35fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.83      0.96      0.89        26\n",
      "        pass       0.98      0.93      0.96        70\n",
      "\n",
      "    accuracy                           0.94        96\n",
      "   macro avg       0.91      0.95      0.92        96\n",
      "weighted avg       0.94      0.94      0.94        96\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[25  1]\n",
      " [ 5 65]]\n"
     ]
    }
   ],
   "source": [
    "# import classification report, confusion matrix, and accuracy score for model evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)) # print accuracy score\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred)) # print classification report\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred)) # print confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d5f89",
   "metadata": {},
   "source": [
    "The model has an accuracy of c.94%, it correctly predicts 94% of student outcomes.\n",
    "\n",
    "The classification report highlights that:\n",
    "\n",
    "1) Precision: When the model says \"fail\", it's correct 83% of the time; when it says \"pass\", it's correct 98%\n",
    "2) Recall: The model detects 96% of actual fails, and 93% of actual passes. This is quite balanced\n",
    "3) F1 score: Overall balance between precision and recall is strong, especially for \"pass\"\n",
    "4) Support: There is evidence of dataset imbalance as there were more \"pass\" cases than \"fail\"\n",
    "\n",
    "The confusion matrix shows that there were only 6 errors in total:\n",
    "\n",
    "- 1 false positive (predicted fail but actually pass)\n",
    "- 5 false negatives (predicted pass but actually fail)\n",
    "\n",
    "The model is slightly more cautious with predicting \"fail\" (reflective of high recall, lower precision).  In other words, it errs on the side of “pass” when unsure — being cautious about labeling students as failing.  This is likely to be due to imbalanced data mentioned above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599d06a",
   "metadata": {},
   "source": [
    "We will next compare the Train performance metrics with the Test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa115fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TRAIN SET ####\n",
      "Accuracy: 0.9450261780104712\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.90      0.89      0.89        99\n",
      "        pass       0.96      0.96      0.96       283\n",
      "\n",
      "    accuracy                           0.95       382\n",
      "   macro avg       0.93      0.93      0.93       382\n",
      "weighted avg       0.94      0.95      0.94       382\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 88  11]\n",
      " [ 10 273]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "#### TEST SET ####\n",
      "Accuracy: 0.9375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        fail       0.83      0.96      0.89        26\n",
      "        pass       0.98      0.93      0.96        70\n",
      "\n",
      "    accuracy                           0.94        96\n",
      "   macro avg       0.91      0.95      0.92        96\n",
      "weighted avg       0.94      0.94      0.94        96\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[25  1]\n",
      " [ 5 65]]\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training and test sets\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "# ---- Train Set Evaluation ----\n",
    "print(\"#### TRAIN SET ####\")\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_train_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ---- Test Set Evaluation ----\n",
    "print(\"#### TEST SET ####\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51beaa9c",
   "metadata": {},
   "source": [
    "It can be seen that the train and test set performances are close, suggesting that there is no overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa9459",
   "metadata": {},
   "source": [
    "# 4 Key prediction drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87ca2d",
   "metadata": {},
   "source": [
    "We will next look to extract the top 10 features influencing pass/fail prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02033110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Coefficient\n",
      "absence_category_high         -2.502428\n",
      "subject_chemistry             -1.460501\n",
      "grade_g-06                     0.982573\n",
      "parent_answered_survey_no     -0.977740\n",
      "grade_g-08                    -0.866755\n",
      "place_of_birth_saudiarabia     0.834076\n",
      "grade_g-04                     0.740109\n",
      "gender_male                   -0.705834\n",
      "nationality_saudiarabia        0.605544\n",
      "subject_science                0.580191\n"
     ]
    }
   ],
   "source": [
    "# Approach adopted from Code Institute's course - print model coefficients through use of a function\n",
    "def logistic_regression_coef(model, columns):\n",
    "    \"\"\"\n",
    "    Prints the coefficients of a logistic regression model.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained logistic regression model.\n",
    "    - columns: The column names corresponding to the coefficients.\n",
    "\n",
    "    \"\"\"\n",
    "    coeff_df = pd.DataFrame(\n",
    "        model.coef_, index=[\"Coefficient\"], columns=columns\n",
    "    ).T.sort_values([\"Coefficient\"], key=abs, ascending=False)\n",
    "    return coeff_df\n",
    "\n",
    "# Extract the one-hot encoder and model from the pipeline\n",
    "encoder = pipe.named_steps['ohe']\n",
    "model = pipe.named_steps['model']\n",
    "\n",
    "# Get encoded feature names\n",
    "encoded_columns = encoder.get_feature_names_out()\n",
    "\n",
    "# Get and print coefficients\n",
    "coef_df = logistic_regression_coef(model, encoded_columns)\n",
    "print(coef_df.head(10))  # Display the top 10 coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cef966",
   "metadata": {},
   "source": [
    "Positive coefficient increases likelihood of pass, whilst negative coefficient increases likelihood of fail.\n",
    "\n",
    "These features will be ranked more highly in building our executive dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab666508",
   "metadata": {},
   "source": [
    "# 5 Summary\n",
    "\n",
    "The classification model that was built using the logistic regression model performs quite well based on the specific train/test split dataset.  There are additional tests and other enhancements that can be explored, and these include:\n",
    "\n",
    "1) hyperparameter tuning within the logistic regression model\n",
    "2) use of different ML model, e.g. RandomForest, XGBoost\n",
    "3) examine approaches to handle data imbalance\n",
    "4) cross validation to improve reliable of the model performance results, via use of multiple train/test split dataset\n",
    "5) feature selection (which can increase model interpretability and improve model performance, even if overfitting is not an issue)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
